#
#   Licensed to the Apache Software Foundation (ASF) under one or more
#   contributor license agreements.  See the NOTICE file distributed with
#   this work for additional information regarding copyright ownership.
#   The ASF licenses this file to You under the Apache License, Version 2.0
#   (the "License"); you may not use this file except in compliance with
#   the License.  You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.
#
# log4j configuration used during build and unit tests
# combines settings for multiple modules

# Uncomment to enable log4j2 to also log
# status = TRACE

packages=org.apache.hadoop.test

rootLogger.level = INFO
rootLogger.appenderRef.console.ref=STDOUT
rootLogger.appenderRef.capture.ref=capture

appender.console.threshold.type=ThresholdFilter
appender.console.threshold.level=ALL
appender.console.name = STDOUT
appender.console.type = Console
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %d{ISO8601} [%t] %-5p %c{2} (%F:%M(%L)) - %m%n

logger.bindingutils.name = org.apache.hadoop.util.dynamic.BindingUtils
logger.bindingutils.level = DEBUG

# used by tests to capture and verify log messages
appender.capture.name = capture
appender.capture.type = CapturingAppender
appender.capture.layout.type = PatternLayout
appender.capture.layout.pattern = %m%n

#
# NameNode metrics logging.
# The default is to retain two namenode-metrics.log files up to 64MB each.
#

appender.nnmetrics.type = RollingRandomAccessFile
appender.nnmetrics.name = NameNodeMetricsLogAppender
appender.nnmetrics.layout.type = PatternLayout
appender.nnmetrics.layout.pattern = %d{ISO8601} %m%n
appender.nnmetrics.fileName = ${sys:hadoop.log.dir}/namenode-metrics.log
appender.nnmetrics.filePattern = ${sys:hadoop.log.dir}/namenode-metrics.log.$i.gz
appender.nnmetrics.immediateFlush = false
appender.nnmetrics.policies.type = Policies
appender.nnmetrics.policies.size.type = SizeBasedTriggeringPolicy
appender.nnmetrics.policies.size.size = 64MB
appender.nnmetrics.strategy.type = DefaultRolloverStrategy
appender.nnmetrics.strategy.max = 1

logger.nnmetrics.type = AsyncLogger
logger.nnmetrics.name = NameNodeMetricsLog
logger.nnmetrics.level = INFO
logger.nnmetrics.additivity = false
logger.nnmetrics.appenderRef.console.ref = STDOUT
logger.nnmetrics.appenderRef.rolling.ref = NameNodeMetricsLogAppender
logger.nnmetrics.appenderRef.capture.ref = capture

#
# DataNode metrics logging.
# The default is to retain two datanode-metrics.log files up to 64MB each.
#

appender.dnmetrics.type = RollingRandomAccessFile
appender.dnmetrics.name = DataNodeMetricsLogAppender
appender.dnmetrics.layout.type = PatternLayout
appender.dnmetrics.layout.pattern = %d{ISO8601} %m%n
appender.dnmetrics.fileName = ${sys:hadoop.log.dir}/datanode-metrics.log
appender.dnmetrics.filePattern = ${sys:hadoop.log.dir}/datanode-metrics.log.$i.gz
appender.dnmetrics.immediateFlush = false
appender.dnmetrics.policies.type = Policies
appender.dnmetrics.policies.size.type = SizeBasedTriggeringPolicy
appender.dnmetrics.policies.size.size = 64MB
appender.dnmetrics.strategy.type = DefaultRolloverStrategy
appender.dnmetrics.strategy.max = 1

logger.dnmetrics.type = AsyncLogger
logger.dnmetrics.name = DataNodeMetricsLog
logger.dnmetrics.level = INFO
logger.dnmetrics.additivity = false
logger.dnmetrics.appenderRef.console.ref = STDOUT
logger.dnmetrics.appenderRef.rolling.ref = DataNodeMetricsLogAppender
logger.dnmetrics.appenderRef.capture.ref = capture

# Supress KMS error log
logger.kmswadl.name = org.glassfish.jersey.server.wadl.internal.generators.WadlGeneratorJAXBGrammarGenerator
logger.kmswadl.level = OFF

#
# hdfs audit logging
#

appender.hdfsaudit.type = RollingRandomAccessFile
appender.hdfsaudit.name = HdfsAuditLogAppender
appender.hdfsaudit.layout.type = PatternLayout
appender.hdfsaudit.layout.pattern = %m%n
appender.hdfsaudit.fileName = ${sys:hadoop.log.dir}/hdfs-audit.log
appender.hdfsaudit.filePattern = ${sys:hadoop.log.dir}/hdfs-audit.log.$i.gz
appender.hdfsaudit.bufferSize = 256
appender.hdfsaudit.immediateFlush = false
appender.hdfsaudit.policies.type = Policies
appender.hdfsaudit.policies.size.type = SizeBasedTriggeringPolicy
appender.hdfsaudit.policies.size.size = ${sys:hdfs.audit.log.maxfilesize:-256MB}
appender.hdfsaudit.strategy.type = DefaultRolloverStrategy
appender.hdfsaudit.strategy.max = ${sys:hdfs.audit.log.maxbackupindex:-20}

logger.hdfsaudit.type = AsyncLogger
logger.hdfsaudit.name = org.apache.hadoop.hdfs.server.namenode.FSNamesystem.audit
logger.hdfsaudit.level = INFO
logger.hdfsaudit.additivity = false
logger.hdfsaudit.appenderRef.console.ref = STDOUT
logger.hdfsaudit.appenderRef.rolling.ref = HdfsAuditLogAppender
logger.hdfsaudit.appenderRef.capture.ref = capture
